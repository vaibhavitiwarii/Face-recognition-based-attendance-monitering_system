{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the prerequisite libraries\n",
    "\n",
    "We will be importing utils.py from https://github.com/iwantooxxoox/Keras-OpenFace/blob/master/utils.py (available with code) which contains utility functions to create the neural network and load the weights assoiated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import LRN2D\n",
    "import utils\n",
    "import pickle\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "import math\n",
    "import boto3\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import smtplib \n",
    "from email.mime.multipart import MIMEMultipart \n",
    "from email.mime.text import MIMEText \n",
    "from email.mime.base import MIMEBase \n",
    "from email import encoders \n",
    "from pygame import mixer\n",
    "\n",
    "# Change these according to your credentials\n",
    "fromaddr =  \"mishtudeep.@gmail.com\"\n",
    "toaddr   =  \"shreedeep.g@mefy.care\" \n",
    "passwd   =  \"Sreeshree123#\"\n",
    "\n",
    "##################################### VOICE RECOGNITION #########################################\n",
    "\n",
    "def recognize():\n",
    "    r = sr.Recognizer()\n",
    "    r.pause_threshold = 0.7\n",
    "    r.energy_threshold = 400\n",
    "    mixer.init()\n",
    "    mixer.music.load('chime1.mp3')\n",
    "    mixer.music.play()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something!\")\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        recognizedAudio =  r.recognize_google(audio)\n",
    "        print(\"You said : \" + recognizedAudio)\n",
    "        mixer.music.load('chime2.mp3')\n",
    "        mixer.music.play()\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "    return recognizedAudio\n",
    "\n",
    "####################################### VOICE PROMPT ############################################\n",
    "        \n",
    "def speak(word):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 150)    \n",
    "    engine.setProperty('volume',1.0)  \n",
    "    voices = engine.getProperty('voices')   \n",
    "    engine.setProperty('voice', voices[1].id)\n",
    "    engine.say(word)\n",
    "    engine.runAndWait()\n",
    "    engine.stop()\n",
    "\n",
    "######################################### SEND MAIL ##############################################\n",
    "\n",
    "def sendMail():\n",
    "    \n",
    "    msg = MIMEMultipart()  \n",
    "    msg['From'] = fromaddr \n",
    "    msg['To'] = toaddr \n",
    "    msg['Subject'] = \"Mail test from Python end.\"\n",
    "    body = \"Hi, I am from MeFy. I am being tested by my creator.\" \n",
    "    msg.attach(MIMEText(body, 'plain')) \n",
    "    filename = \"MeFy1.jpg\"\t\t\t\t\t\t\t\t  # Provide the file name\n",
    "    attachment = open(\"C:\\\\Users\\\\SREEDEEP\\\\Documents\\\\face\\\\Mail sender\\\\MeFy1.jpg\", \"rb\")    # Provide the complete address to the file within \" \"\n",
    "    p = MIMEBase('application', 'octet-stream') \n",
    "    p.set_payload((attachment).read()) \n",
    "    encoders.encode_base64(p) \n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)  \n",
    "    msg.attach(p) \n",
    "    s = smtplib.SMTP('smtp.gmail.com', port=587, timeout=25) \n",
    "    s.starttls() \n",
    "    s.login(fromaddr, passwd) \n",
    "    text = msg.as_string() \n",
    "    s.sendmail(fromaddr, toaddr, text) \n",
    "    s.quit()\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~ EXECUTION BEGINS FROM HERE ~~~~~~~~~~~#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the neural network model\n",
    "The model here constructed is based on FaceNet's Inception model.\n",
    "\n",
    "The implementation of model is available at: https://github.com/iwantooxxoox/Keras-OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInput = Input(shape=(96, 96, 3))\n",
    "\n",
    "x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "x = Lambda(LRN2D, name='lrn_1')(x)\n",
    "x = Conv2D(64, (1, 1), name='conv2')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = Conv2D(192, (3, 3), name='conv3')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Lambda(LRN2D, name='lrn_2')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "# Inception3a\n",
    "inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n",
    "inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "\n",
    "inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n",
    "inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "\n",
    "inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n",
    "inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
    "inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
    "inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n",
    "\n",
    "inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n",
    "inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
    "inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
    "\n",
    "inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n",
    "\n",
    "# Inception3b\n",
    "inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n",
    "inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "\n",
    "inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n",
    "inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "\n",
    "inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n",
    "inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n",
    "inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
    "inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
    "inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n",
    "\n",
    "inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n",
    "inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
    "inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
    "\n",
    "inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n",
    "\n",
    "# Inception3c\n",
    "inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_3x3',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_3c_5x5 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n",
    "inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n",
    "\n",
    "inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n",
    "\n",
    "#inception 4a\n",
    "inception_4a_3x3 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=192,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_4a_5x5 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n",
    "inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n",
    "inception_4a_pool = utils.conv2d_bn(inception_4a_pool,\n",
    "                                   layer='inception_4a_pool',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "inception_4a_1x1 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n",
    "\n",
    "#inception4e\n",
    "inception_4e_3x3 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_3x3',\n",
    "                                   cv1_out=160,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "inception_4e_5x5 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_5x5',\n",
    "                                   cv1_out=64,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=128,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n",
    "inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n",
    "\n",
    "inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n",
    "\n",
    "#inception5a\n",
    "inception_5a_3x3 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n",
    "inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n",
    "inception_5a_pool = utils.conv2d_bn(inception_5a_pool,\n",
    "                                   layer='inception_5a_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5a_1x1 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "\n",
    "inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n",
    "\n",
    "#inception_5b\n",
    "inception_5b_3x3 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n",
    "inception_5b_pool = utils.conv2d_bn(inception_5b_pool,\n",
    "                                   layer='inception_5b_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n",
    "\n",
    "inception_5b_1x1 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n",
    "\n",
    "av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n",
    "reshape_layer = Flatten()(av_pool)\n",
    "dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "\n",
    "\n",
    "# Final Model\n",
    "model = Model(inputs=[myInput], outputs=norm_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  The Triplet Loss\n",
    "\n",
    "For an image $x$, we denote its encoding $f(x)$, where $f$ is the function computed by the neural network.\n",
    "\n",
    "\n",
    "<!--\n",
    "We will also add a normalization step at the end of our model so that $\\mid \\mid f(x) \\mid \\mid_2 = 1$ (means the vector of encoding should be of norm 1).\n",
    "!-->\n",
    "\n",
    "Training will use triplets of images $(A, P, N)$:  \n",
    "\n",
    "- A is an \"Anchor\" image--a picture of a person. \n",
    "- P is a \"Positive\" image--a picture of the same person as the Anchor image.\n",
    "- N is a \"Negative\" image--a picture of a different person than the Anchor image.\n",
    "\n",
    "These triplets are picked from our training dataset. We will write $(A^{(i)}, P^{(i)}, N^{(i)})$ to denote the $i$-th training example. \n",
    "\n",
    "You'd like to make sure that an image $A^{(i)}$ of an individual is closer to the Positive $P^{(i)}$ than to the Negative image $N^{(i)}$) by at least a margin $\\alpha$:\n",
    "\n",
    "$$\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 + \\alpha < \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$$\n",
    "\n",
    "You would thus like to minimize the following \"triplet cost\":\n",
    "\n",
    "$$\\mathcal{J} = \\sum^{N}_{i=1} \\large[ \\small \\underbrace{\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2}_\\text{(1)} - \\underbrace{\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2}_\\text{(2)} + \\alpha \\large ] \\small_+ \\tag{3}$$\n",
    "\n",
    "Here, we are using the notation \"$[z]_+$\" to denote $max(z,0)$.  \n",
    "\n",
    "Notes:\n",
    "- The term (1) is the squared distance between the anchor \"A\" and the positive \"P\" for a given triplet; you want this to be small. \n",
    "- The term (2) is the squared distance between the anchor \"A\" and the negative \"N\" for a given triplet, you want this to be relatively large, so it thus makes sense to have a minus sign preceding it. \n",
    "- $\\alpha$ is called the margin. It is a hyperparameter that you should pick manually. We will use $\\alpha = 0.2$. \n",
    "\n",
    "Most implementations also normalize the encoding vectors  to have norm equal one (i.e., $\\mid \\mid f(img)\\mid \\mid_2$=1); you won't have to worry about that here.\n",
    "\n",
    "**Exercise**: Implement the triplet loss as defined by formula (3). Here are the 4 steps:\n",
    "1. Compute the distance between the encodings of \"anchor\" and \"positive\": $\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2$\n",
    "2. Compute the distance between the encodings of \"anchor\" and \"negative\": $\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$\n",
    "3. Compute the formula per training example: $ \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2 + \\alpha$\n",
    "3. Compute the full formula by taking the max with zero and summing over the training examples:\n",
    "$$\\mathcal{J} = \\sum^{N}_{i=1} \\large[ \\small \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2+ \\alpha \\large ] \\small_+ \\tag{3}$$\n",
    "\n",
    "Useful functions: `tf.reduce_sum()`, `tf.square()`, `tf.subtract()`, `tf.add()`, `tf.reduce_mean`, `tf.maximum()`.\n",
    "\n",
    "## Note:\n",
    "\n",
    "Euclidean norm (Euclidean diatance):\n",
    "\n",
    "$$ \\left \\| X \\right \\|_2 := \\sqrt{x_1^2 + x_2^2 + x_3^2 + ... + x_n^2}, $$\n",
    "\n",
    "$$ \\left \\| X \\right \\|_2^2 := \\sum_{i=1}^{n}x_i^2. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: triplet_loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive))\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative))\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.maximum(basic_loss, 0)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "\n",
    "#model.load_weights('nn4.small2.v7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model with pretrained weights\n",
    "\n",
    "FaceNet is trained by minimizing the triplet loss. I will be  loading a previously trained model. weights are avaiable at https://github.com/iwantooxxoox/Keras-OpenFace in the \"weights\" folder which is also provided in this source.\n",
    "\n",
    "This can take a couple of minutes to execute and depends on the speed of your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load weights from csv files (which was exported from Openface torch model)\n",
    "# weights = utils.weights\n",
    "# weights_dict = utils.load_weights()\n",
    "\n",
    "# # Set layer weights of the model\n",
    "# for name in weights:\n",
    "#   if model.get_layer(name) != None:\n",
    "#     model.get_layer(name).set_weights(weights_dict[name])\n",
    "#   elif model.get_layer(name) != None:\n",
    "#     model.get_layer(name).set_weights(weights_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About <font color=blue>image_to_embedding</font> function        \n",
    "When the model is loaded with pre trained weights, then we can create the **128 dimensional embedding vectors** for all the face images stored in the \"images\" folder. **\"image_to_embedding\"** function pass an image to the Inception network to generate the embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_embedding(image, model):\n",
    "    #image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_AREA) \n",
    "    image = cv2.resize(image, (96, 96)) \n",
    "    img = image[...,::-1]\n",
    "    img = np.around(np.transpose(img, (0,1,2))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About <font color=blue>recognize_face</font> function\n",
    "This function calculate similarity between the captured image and the images that are already been stored. It passes the image to the trained neural network to generate its embedding vector. Which is then compared with all the embedding vectors of the images stored by calculating L2 Euclidean distance. \n",
    "\n",
    "If the minimum L2 distance between two embeddings is less than a threshpld (here I have taken the threashhold as .68 (which can be adjusted) then we have a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(face_image, input_embeddings, model):\n",
    "\n",
    "    embedding = image_to_embedding(face_image, model)\n",
    "    \n",
    "    minimum_distance = 200\n",
    "    name = None\n",
    "    \n",
    "    # Loop over  names and encodings.\n",
    "    for (input_name, input_embedding) in input_embeddings.items():\n",
    "        \n",
    "       \n",
    "        euclidean_distance = np.linalg.norm(embedding-input_embedding)\n",
    "        #euclidean_distance = np.sum(np.square(embedding-input_embedding))\n",
    "\n",
    "        print('Euclidean distance from %s is %s' %(input_name, euclidean_distance))\n",
    "\n",
    "        \n",
    "        if euclidean_distance < minimum_distance:\n",
    "            minimum_distance = euclidean_distance\n",
    "            name = input_name\n",
    "    \n",
    "    if minimum_distance < 0.70:\n",
    "        return str(name[:-2])\n",
    "    else:\n",
    "        return str('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About <font color=blue>create_input_image_embeddings</font> function\n",
    "This function generates 128 dimensional image ebeddings of all the images stored in the \"images\" directory by feed forwarding the images to a trained neural network. It creates a dictionary with key as the name of the face and value as embedding\n",
    "\n",
    "\n",
    "## About <font color=blue>recognize_faces_in_cam</font> function\n",
    "This function capture image from the webcam, detect a face in it and crop the image to have a face only, which is then passed to recognize_face function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client('s3')\n",
    "    #Read the object stored in key 'myList001'\n",
    "    object = s3.get_object(Bucket='maitibucket',Key='embeddings')\n",
    "    serializedObject = object['Body'].read()\n",
    "    #Deserialize the retrieved object\n",
    "    database = pickle.loads(serializedObject)\n",
    "except:\n",
    "    database={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst),key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def create_input_image_embeddings():\n",
    "    input_embeddings = {}\n",
    "\n",
    "    for file in glob.glob(\"images/*\"):\n",
    "        person_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        image_file = cv2.imread(file, 1)\n",
    "        input_embeddings[person_name] = image_to_embedding(image_file, model)\n",
    "\n",
    "    return input_embeddings\n",
    "\n",
    "def recognize_faces_in_cam(input_embeddings=database):\n",
    "    \n",
    "\n",
    "    cv2.namedWindow(\"Face Recognizer\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "   \n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    count=0\n",
    "    lst=[]\n",
    "    while vc.isOpened():\n",
    "        _, frame = vc.read()\n",
    "        img = frame\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        \n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Loop through all the faces detected \n",
    "        identities = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = x+w\n",
    "            y2 = y+h\n",
    "\n",
    "           \n",
    "            \n",
    "            face_image = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)]    \n",
    "            identity = recognize_face(face_image, input_embeddings, model)\n",
    "            \n",
    "            \n",
    "\n",
    "            if identity is not None:\n",
    "                img = cv2.rectangle(frame,(x1, y1),(x2, y2),(0,255,0),2)\n",
    "                cv2.putText(img, str(identity), (x1+5,y1-5), font, 1, (0,255,0), 2)\n",
    "                lst.append(identity)\n",
    "        count+=1\n",
    "            \n",
    "        key = cv2.waitKey(100)\n",
    "        cv2.imshow(\"Face Recognizer\", img)\n",
    "        if(count>=10):\n",
    "            break\n",
    "        elif key == 27: # exit on ESC\n",
    "            break\n",
    "    vc.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if(len(lst)!=0):\n",
    "        user=most_common(lst)\n",
    "    else:\n",
    "        user='noface'\n",
    "    return user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing the face image\n",
    "Following code captures 10 face images of the person. They all are stored in **\"images\"** folder with the name User_1 to User_10. Select a good captured image from the set of 10 images. Rename it with the name of person and delete rest of them. This image will be used for recognizing the the identity of the person using one shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import portrait, inch\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Image\n",
    "import random\n",
    "\n",
    "def exportPdf(data_dict):\n",
    "    file_name='Employee Details/'+data_dict['emp_id']+\".pdf\"\n",
    "    c = canvas.Canvas(file_name,pagesize=portrait(A4))\n",
    "    \n",
    "    c.setFont('Helvetica',20,leading=None)\n",
    "    c.setFillColorRGB(0.2,0.286,0.376)\n",
    "    c.drawString(50,750,\"Company Name\")\n",
    "    \n",
    "    c.setFillColorRGB(0.4,0.4,0.4)\n",
    "    c.setFont('Helvetica',10,leading=None)\n",
    "    c.drawString(52,736,\"Address\")\n",
    "    c.drawString(52,724,\"Zip code\")\n",
    "    c.drawString(52,712,\"Phone Number\")\n",
    "    \n",
    "    c.setFillColorRGB(0.96,0.40,0.14)\n",
    "    c.setFont('Helvetica-Bold',34,leading=None)\n",
    "    c.drawString(50,660,\"Employee Details\")\n",
    "    \n",
    "    c.setFont('Helvetica-Bold',16,leading=None)\n",
    "    c.setFillColorRGB(0.2,0.286,0.376)\n",
    "    c.drawString(50,620,\"EMPLOYEE ID: \"+data_dict['emp_id'])\n",
    "    \n",
    "    c.setFillColorRGB(0,0,0)\n",
    "    c.setFont('Helvetica',12,leading=None)\n",
    "    c.drawString(52,600,\"Employee Name: \"+data_dict['name'])\n",
    "    c.drawString(52,585,\"Email ID: \"+data_dict['e_mail'])\n",
    "    c.drawString(52,570,\"Phone Number: \"+data_dict['contact_number'])\n",
    "    \n",
    "    c.setFont('Helvetica-Bold',16,leading=None)\n",
    "    c.setFillColorRGB(0.2,0.286,0.376)\n",
    "    c.drawString(50,540,\"PERSONAL DETAILS\")\n",
    "    \n",
    "    c.setFont('Helvetica',12,leading=None)\n",
    "    c.setFillColorRGB(0,0,0)\n",
    "    c.drawString(52,520,\"AADHAAR NUMBER: \"+data_dict['uid'])\n",
    "    c.drawString(52,505,\"Name: \"+data_dict['name'])\n",
    "    c.drawString(52,490,\"Gender: \"+data_dict['gender'])\n",
    "    c.drawString(52,475,\"YOB: \"+data_dict['yob'])\n",
    "    c.drawString(52,460,\"Guardian's Name: \"+data_dict['gname'])\n",
    "    c.drawString(52,445,\"House: \"+data_dict['house'])\n",
    "    c.drawString(52,430,\"Street: \"+data_dict['street'])\n",
    "    c.drawString(52,415,\"Location: \"+data_dict['loc'])\n",
    "    c.drawString(52,400,\"VTC: \"+data_dict['vtc'])\n",
    "    c.drawString(52,385,\"P.O.: \"+data_dict['po'])\n",
    "    c.drawString(52,370,\"District: \"+data_dict['dist'])\n",
    "    c.drawString(52,355,\"Subdistrict: \"+data_dict['subdist'])\n",
    "    c.drawString(52,340,\"State: \"+data_dict['state'])\n",
    "    c.drawString(52,325,\"Pin Code: \"+data_dict['pc'])\n",
    "    c.drawString(52,310,\"Date of birth: \"+data_dict['dob'])\n",
    "    \n",
    "    image_file='images/'+data_dict['emp_id']+'_'+str(random.randint(0,9))+'.jpg'\n",
    "    c.drawImage(image_file, 400, 510,width=2*inch,height=2*inch)\n",
    "    \n",
    "    date_time=datetime.datetime.now().isoformat()\n",
    "    c.setFont('Helvetica',12,leading=None)\n",
    "    c.setFillColorRGB(0.2,0.286,0.376)\n",
    "    c.drawString(400,480,\"Date of joining: \"+date_time[:10])\n",
    "    c.drawString(400,465,\"Time: \"+date_time[11:19])\n",
    "    \n",
    "    c.showPage()\n",
    "    c.save()\n",
    "    \n",
    "    s3=boto3.client('s3')\n",
    "    s3.upload_file(file_name,'maitibucket',file_name)\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureImages(data_dict):\n",
    "    \n",
    "    e_id=data_dict['emp_id']\n",
    "    e_name=data_dict['name']\n",
    "    email=data_dict['e_mail']\n",
    "    speak(\"Hello \"+e_name+\". Welcome to face recognition system. We are going to take some photos. Get ready.\")\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    count = 0\n",
    "    while(True):\n",
    "        ret, img = cam.read()\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = x+w\n",
    "            y2 = y+h\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (255,255,255), 2)     \n",
    "        # Save the captured image into the datasets folder\n",
    "            path=\"images/\"+e_id+\"_\" + str(count) + \".jpg\"\n",
    "            cv2.imwrite(path, img[y1:y2,x1:x2])\n",
    "            cv2.imshow('image', img)\n",
    "        #input_embeddings[user]=image_to_embedding(cv2.imread(path),model)\n",
    "            count += 1\n",
    "        k = cv2.waitKey(200) & 0xff # Press 'ESC' for exiting video\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif count >= 10: # Take 30 face sample and stop video\n",
    "             break\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    for file in glob.glob(\"images/\"+e_id+\"_*\"):\n",
    "            person_name = os.path.splitext(os.path.basename(file))[0]\n",
    "            image_file = cv2.imread(file, 1)\n",
    "            database[person_name] = image_to_embedding(image_file, model)\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    #Serialize the object \n",
    "    serializedListObject = pickle.dumps(database)\n",
    "    #Write to Bucket named 'maitibucket' and \n",
    "    #Store the list using key embeddings\n",
    "    s3.put_object(Bucket='maitibucket',Key='embeddings',Body=serializedListObject)\n",
    "\n",
    "    sheet=client.open(\"Attendance System\").get_worksheet(13)\n",
    "    sheet.insert_row(list(data_dict.values()),3)\n",
    "    for sheet_no in range(12):\n",
    "        sheet=client.open(\"Attendance System\").get_worksheet(sheet_no)\n",
    "        sheet.insert_row([e_id,e_name,email],5)\n",
    "    exportPdf(data_dict)\n",
    "    for file in glob.glob(\"images/\"+e_id+\"_*\"):\n",
    "        os.remove(file)\n",
    "    speak(\"Successfully registered\")\n",
    "    messagebox.showinfo(\"Registration Successful\",\"Your Employee ID is:\"+data_dict['emp_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popup(data_dict):\n",
    "    msg=\"Name: \"+data_dict['name']+\"\\nAadhar No: \"+data_dict['uid']+\"\\nGender: \"+data_dict['gender']+\"\\nAddress: \"+data_dict['house']+\", \"+data_dict['street']+\", \"+data_dict['loc']+\", \"+data_dict['vtc']+\", \"+data_dict['dist']+\", \"+data_dict['state']+\"-\"+data_dict['pc']+\"\\nDate of birth: \"+data_dict['dob']+\"\\nEmail ID: \"+data_dict['e_mail']+\"\\nContact No: \"+data_dict['contact_number']\n",
    "    proceed=\"\\n\\nPlease press 'OK' to confirm the details and proceed to take pictures.\"\n",
    "    response=messagebox.askokcancel(\"Verify your details\",msg+proceed)\n",
    "    #speak(\"Verify your details. Press ok to confirm and proceed to the next step to take pictures.\")\n",
    "    if(response==1):\n",
    "        captureImages(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyzbar.pyzbar as pyzbar\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def QrScanner():\n",
    "    speak(\"Please hold the QR code in your adhar card in front of camera\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    flag=None\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "    \n",
    "        decodedObjects = pyzbar.decode(frame)\n",
    "        for obj in decodedObjects:\n",
    "            data=obj.data\n",
    "            flag=obj.type\n",
    "            #cv2.putText(frame, str(obj.data), (50, 50), font, 2, (255, 0, 0), 3)\n",
    "            (x,y,w,h)=obj.rect\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h), (255,0,0), 2)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    " \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        elif (flag=='QRCODE'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    myroot=ET.fromstring(data)\n",
    "    data_dict=myroot.attrib\n",
    "    data_dict['e_mail']=email_entry.get()\n",
    "    data_dict['contact_number']=contact_entry.get()\n",
    "    date_time=datetime.datetime.now().isoformat()\n",
    "    date_time=date_time[2:4]+date_time[5:7]+date_time[8:10]+date_time[11:13]+date_time[14:16]+date_time[17:19]+date_time[20:]\n",
    "    data_dict['emp_id']=date_time\n",
    "    #print(data_dict)\n",
    "    popup(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Real time face recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no record found in sheets\n",
      "Euclidean distance from 190926142554436691_0 is 0.695499\n",
      "Euclidean distance from 190926142554436691_1 is 0.544795\n",
      "Euclidean distance from 190926142554436691_2 is 0.64067\n",
      "Euclidean distance from 190926142554436691_3 is 0.652384\n",
      "Euclidean distance from 190926142554436691_4 is 0.589723\n",
      "Euclidean distance from 190926142554436691_5 is 0.585716\n",
      "Euclidean distance from 190926142554436691_6 is 0.697164\n",
      "Euclidean distance from 190926142554436691_7 is 0.646467\n",
      "Euclidean distance from 190926142554436691_8 is 0.616582\n",
      "Euclidean distance from 190926142554436691_9 is 0.671337\n",
      "Euclidean distance from 190926142554436691_0 is 0.560117\n",
      "Euclidean distance from 190926142554436691_1 is 0.450971\n",
      "Euclidean distance from 190926142554436691_2 is 0.59729\n",
      "Euclidean distance from 190926142554436691_3 is 0.61161\n",
      "Euclidean distance from 190926142554436691_4 is 0.565972\n",
      "Euclidean distance from 190926142554436691_5 is 0.543875\n",
      "Euclidean distance from 190926142554436691_6 is 0.643069\n",
      "Euclidean distance from 190926142554436691_7 is 0.625514\n",
      "Euclidean distance from 190926142554436691_8 is 0.591746\n",
      "Euclidean distance from 190926142554436691_9 is 0.660856\n",
      "Euclidean distance from 190926142554436691_0 is 0.693081\n",
      "Euclidean distance from 190926142554436691_1 is 0.558228\n",
      "Euclidean distance from 190926142554436691_2 is 0.686283\n",
      "Euclidean distance from 190926142554436691_3 is 0.689377\n",
      "Euclidean distance from 190926142554436691_4 is 0.655729\n",
      "Euclidean distance from 190926142554436691_5 is 0.6473\n",
      "Euclidean distance from 190926142554436691_6 is 0.713209\n",
      "Euclidean distance from 190926142554436691_7 is 0.708981\n",
      "Euclidean distance from 190926142554436691_8 is 0.678539\n",
      "Euclidean distance from 190926142554436691_9 is 0.73031\n",
      "Euclidean distance from 190926142554436691_0 is 0.694095\n",
      "Euclidean distance from 190926142554436691_1 is 0.559424\n",
      "Euclidean distance from 190926142554436691_2 is 0.671026\n",
      "Euclidean distance from 190926142554436691_3 is 0.674245\n",
      "Euclidean distance from 190926142554436691_4 is 0.636468\n",
      "Euclidean distance from 190926142554436691_5 is 0.636546\n",
      "Euclidean distance from 190926142554436691_6 is 0.703899\n",
      "Euclidean distance from 190926142554436691_7 is 0.690128\n",
      "Euclidean distance from 190926142554436691_8 is 0.663392\n",
      "Euclidean distance from 190926142554436691_9 is 0.715371\n",
      "Euclidean distance from 190926142554436691_0 is 0.723966\n",
      "Euclidean distance from 190926142554436691_1 is 0.612353\n",
      "Euclidean distance from 190926142554436691_2 is 0.730994\n",
      "Euclidean distance from 190926142554436691_3 is 0.743389\n",
      "Euclidean distance from 190926142554436691_4 is 0.68122\n",
      "Euclidean distance from 190926142554436691_5 is 0.671032\n",
      "Euclidean distance from 190926142554436691_6 is 0.772298\n",
      "Euclidean distance from 190926142554436691_7 is 0.727207\n",
      "Euclidean distance from 190926142554436691_8 is 0.699224\n",
      "Euclidean distance from 190926142554436691_9 is 0.75515\n",
      "Euclidean distance from 190926142554436691_0 is 0.718827\n",
      "Euclidean distance from 190926142554436691_1 is 0.623741\n",
      "Euclidean distance from 190926142554436691_2 is 0.732074\n",
      "Euclidean distance from 190926142554436691_3 is 0.749093\n",
      "Euclidean distance from 190926142554436691_4 is 0.66932\n",
      "Euclidean distance from 190926142554436691_5 is 0.663312\n",
      "Euclidean distance from 190926142554436691_6 is 0.799886\n",
      "Euclidean distance from 190926142554436691_7 is 0.738002\n",
      "Euclidean distance from 190926142554436691_8 is 0.712892\n",
      "Euclidean distance from 190926142554436691_9 is 0.75847\n",
      "Euclidean distance from 190926142554436691_0 is 0.727454\n",
      "Euclidean distance from 190926142554436691_1 is 0.62422\n",
      "Euclidean distance from 190926142554436691_2 is 0.718722\n",
      "Euclidean distance from 190926142554436691_3 is 0.732192\n",
      "Euclidean distance from 190926142554436691_4 is 0.66537\n",
      "Euclidean distance from 190926142554436691_5 is 0.651513\n",
      "Euclidean distance from 190926142554436691_6 is 0.780453\n",
      "Euclidean distance from 190926142554436691_7 is 0.731057\n",
      "Euclidean distance from 190926142554436691_8 is 0.707716\n",
      "Euclidean distance from 190926142554436691_9 is 0.738794\n",
      "Euclidean distance from 190926142554436691_0 is 0.687206\n",
      "Euclidean distance from 190926142554436691_1 is 0.555706\n",
      "Euclidean distance from 190926142554436691_2 is 0.653791\n",
      "Euclidean distance from 190926142554436691_3 is 0.672359\n",
      "Euclidean distance from 190926142554436691_4 is 0.610027\n",
      "Euclidean distance from 190926142554436691_5 is 0.608859\n",
      "Euclidean distance from 190926142554436691_6 is 0.712158\n",
      "Euclidean distance from 190926142554436691_7 is 0.664911\n",
      "Euclidean distance from 190926142554436691_8 is 0.635948\n",
      "Euclidean distance from 190926142554436691_9 is 0.691086\n",
      "Euclidean distance from 190926142554436691_0 is 0.635248\n",
      "Euclidean distance from 190926142554436691_1 is 0.502379\n",
      "Euclidean distance from 190926142554436691_2 is 0.630777\n",
      "Euclidean distance from 190926142554436691_3 is 0.640348\n",
      "Euclidean distance from 190926142554436691_4 is 0.582414\n",
      "Euclidean distance from 190926142554436691_5 is 0.572683\n",
      "Euclidean distance from 190926142554436691_6 is 0.680168\n",
      "Euclidean distance from 190926142554436691_7 is 0.645208\n",
      "Euclidean distance from 190926142554436691_8 is 0.61884\n",
      "Euclidean distance from 190926142554436691_9 is 0.669965\n",
      "Euclidean distance from 190926142554436691_0 is 0.697914\n",
      "Euclidean distance from 190926142554436691_1 is 0.570231\n",
      "Euclidean distance from 190926142554436691_2 is 0.721586\n",
      "Euclidean distance from 190926142554436691_3 is 0.72117\n",
      "Euclidean distance from 190926142554436691_4 is 0.663094\n",
      "Euclidean distance from 190926142554436691_5 is 0.653649\n",
      "Euclidean distance from 190926142554436691_6 is 0.768233\n",
      "Euclidean distance from 190926142554436691_7 is 0.743486\n",
      "Euclidean distance from 190926142554436691_8 is 0.716888\n",
      "Euclidean distance from 190926142554436691_9 is 0.759233\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "credentials=ServiceAccountCredentials.from_json_keyfile_name('Attendance-72970c144e04.json',scope)\n",
    "client=gspread.authorize(credentials)\n",
    "\n",
    "window=Tk()\n",
    "window.title(\"Face Recognition\")\n",
    "window.resizable(0,0)\n",
    "banner=tkinter.PhotoImage(file='C:/Users/Sourav/PROJECTS/Face Recognition/Face-recognition (implementation of Facenet)/facial-recognition-ibm-1440x920.gif')\n",
    "#tkinter.Label(window,image=banner) .grid(row=0,column=0,sticky=E)\n",
    "w = banner.width()\n",
    "h = banner.height()\n",
    "\n",
    "# size the window so the image will fill it\n",
    "window.geometry(\"%dx%d+50+30\" % (w, h))\n",
    "\n",
    "cv = tkinter.Canvas(width=w, height=h)\n",
    "cv.pack(side='top', fill='both', expand='yes')\n",
    "cv.create_image(0, 0, image=banner,anchor='nw')\n",
    "# add canvas text at coordinates x=15, y=20\n",
    "# anchor='nw' implies upper left corner coordinates\n",
    "cv.create_text(20, 20, text=\"Face Recognition Attendance System\",font=(\"agency fb bold\",28), fill=\"white\", anchor='nw')\n",
    "cv.create_text(20, 90, text=\"New Registration\",font=(\"agency fb bold\",22), fill=\"white\", anchor='nw')\n",
    "\n",
    "cv.create_text(20, 130, text=\"Enter your contact number:\",font=(\"agency fb bold\",14), fill=\"white\", anchor='nw')\n",
    "contact_entry=Entry(cv, width=40,bg='white')\n",
    "contact_entry.place(x=20,y=160)\n",
    "\n",
    "cv.create_text(20, 210, text=\"Enter your Email ID:\",font=(\"agency fb bold\",14), fill=\"white\", anchor='sw')\n",
    "email_entry=Entry(cv, width=40,bg='white')\n",
    "email_entry.place(x=20,y=220)\n",
    "\n",
    "# cv.create_text(20, 270, text=\"Enter your email ID:\",font=(\"agency fb bold\",14), fill=\"white\", anchor='sw')\n",
    "# email_entry=Entry(cv, width=40,bg='white')\n",
    "# email_entry.place(x=20,y=280)\n",
    "\n",
    "\n",
    "def register():\n",
    "    if (contact_entry.get() and email_entry.get()):\n",
    "        QrScanner()\n",
    "    else:\n",
    "        speak(\"Please enter your details in the text box\")\n",
    "        #msg=messagebox.showinfo(\"Error\",\"Please enter your name in the text box\")\n",
    "        \n",
    "def checkIn():\n",
    "    date_time=datetime.datetime.now().isoformat()\n",
    "    if((int(date_time[11:13])+int(date_time[14:16])/60)>20):#Checkin time threshold\n",
    "            speak(\"Sorry. Time period to enter into the office has exceeded.\")\n",
    "            return \"midin\"\n",
    "    else:\n",
    "        user=recognize_faces_in_cam(database)\n",
    "        sheet_no=int(date_time[5:7])-1\n",
    "        sheet=client.open(\"Attendance System\").get_worksheet(sheet_no)\n",
    "        try:\n",
    "            row_no=sheet.col_values(1).index(user) + 1\n",
    "            col_no=(int(date_time[8:10]))*6-2\n",
    "            entry=sheet.cell(row_no,col_no).value.split(':')\n",
    "        except:\n",
    "            print(\"no record found in sheets\")\n",
    "        \n",
    "        try:\n",
    "            if(user=='Unknown'):\n",
    "                speak(\"Sorry. No record found. If you are a new user, please register yourself.\")\n",
    "            elif(user=='noface'):\n",
    "                speak(\"Sorry. No face detected. Try again.\")\n",
    "            elif(entry[0]!=''):\n",
    "                speak(\"Hi \"+sheet.cell(row_no,2).value+\", you have already checked in at \"+entry[0]+\" \"+entry[1]+\" hours.\")\n",
    "                return \"midin\"\n",
    "            else:\n",
    "                sheet.update_cell(row_no,col_no,date_time[11:])\n",
    "                speak(\"Hi \"+sheet.cell(row_no,2).value+\", Welcome.\")\n",
    "        except:\n",
    "            speak(\"Something went wrong. Please Try again.\")\n",
    "        \n",
    "def checkOut():\n",
    "    user=recognize_faces_in_cam(database)\n",
    "    try:\n",
    "        date_time=datetime.datetime.now().isoformat()\n",
    "        sheet_no=int(date_time[5:7])-1\n",
    "        sheet=client.open(\"Attendance System\").get_worksheet(sheet_no)\n",
    "        try:\n",
    "            row_no=sheet.col_values(1).index(user) + 1\n",
    "            col_no=(int(date_time[8:10]))*6-1\n",
    "            entry=sheet.cell(row_no,col_no-1).value.split(':')\n",
    "            min_exit_time=float((int(entry[0])+int(entry[1])/60)+0) #checkout time threshold\n",
    "            exit=sheet.cell(row_no,col_no).value.split(':')\n",
    "        except:\n",
    "            print(\"no record found in sheets\")\n",
    "        if(user=='Unknown'):\n",
    "            speak(\"Sorry. No record found. If you are a new user, please register yourself.\")\n",
    "        elif(user=='noface'):\n",
    "            speak(\"Sorry. No face detected. Try again.\")\n",
    "        elif(entry[0]==''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you did not check in yet today.\")\n",
    "        elif((int(date_time[11:13])+int(date_time[14:16])/60)<min_exit_time):\n",
    "            speak(\"Sorry. You can not leave before \"+str(int(min_exit_time))+\" \"+str(math.ceil((min_exit_time*60)%60))+\" hours.\")\n",
    "            return 'midout'\n",
    "        elif(exit[0]!=''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you have already checked out at \"+exit[0]+\" \"+exit[1]+\" hours.\")\n",
    "        else:\n",
    "            sheet.update_cell(row_no,col_no,datetime.datetime.now().isoformat()[11:])\n",
    "            speak(\"Good bye Mr. \"+sheet.cell(row_no,2).value)\n",
    "    except:\n",
    "        speak(\"Something went wrong. Please Try again.\")\n",
    "        \n",
    "def midOut():\n",
    "    user=recognize_faces_in_cam(database)\n",
    "    try:\n",
    "        date_time=datetime.datetime.now().isoformat()\n",
    "        sheet_no=int(date_time[5:7])-1\n",
    "        sheet=client.open(\"Attendance System\").get_worksheet(sheet_no)\n",
    "        try:\n",
    "            row_no=sheet.col_values(1).index(user) + 1\n",
    "            col_no=(int(date_time[8:10]))*6\n",
    "            entry=sheet.cell(row_no,col_no-2).value.split(':')\n",
    "            exit=sheet.cell(row_no,col_no-1).value.split(':')\n",
    "        except:\n",
    "            print(\"no record found in sheets\")\n",
    "        if(user=='Unknown'):\n",
    "            speak(\"Sorry. No record found. If you are a new user, please register yourself.\")\n",
    "        elif(user=='noface'):\n",
    "            speak(\"Sorry. No face detected. Try again.\")\n",
    "        elif(entry[0]==''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you did not check in yet today.\")\n",
    "        elif(exit[0]!=''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you have already checked out for today at \"+exit[0]+\" \"+exit[1]+\" hours.\")\n",
    "        else:\n",
    "            sheet.update_cell(row_no,col_no,datetime.datetime.now().isoformat()[11:])\n",
    "            speak(\"Hi Mr. \"+sheet.cell(row_no,2).value+\", please return to the office within thirty minutes.\")\n",
    "    except:\n",
    "        speak(\"Something went wrong. Please Try again.\")\n",
    "        \n",
    "\n",
    "def midIn():\n",
    "    date_time=datetime.datetime.now().isoformat()\n",
    "    user=recognize_faces_in_cam(database)\n",
    "    sheet_no=int(date_time[5:7])-1\n",
    "    sheet=client.open(\"Attendance System\").get_worksheet(sheet_no)\n",
    "    try:\n",
    "        row_no=sheet.col_values(1).index(user) + 1\n",
    "        col_no=(int(date_time[8:10]))*6+1\n",
    "        entry=sheet.cell(row_no,col_no-3).value\n",
    "        mid_out=sheet.cell(row_no,col_no-1).value\n",
    "        exit=sheet.cell(row_no,col_no-2).value.split(':')\n",
    "    except:\n",
    "        print(\"no record found in sheets\")\n",
    "        \n",
    "    try:\n",
    "        if(user=='Unknown'):\n",
    "            speak(\"Sorry. No record found. If you are a new user, please register yourself.\")\n",
    "        elif(user=='noface'):\n",
    "            speak(\"Sorry. No face detected. Try again.\")\n",
    "        elif(entry==''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you did not check in yet today.\")\n",
    "        elif(exit[0]!=''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you have already checked out for today at \"+exit[0]+\" \"+exit[1]+\" hours.\")\n",
    "        elif(mid_out==''):\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", you did not mid check out today\")\n",
    "        else:\n",
    "            sheet.update_cell(row_no,col_no,date_time[11:])\n",
    "            speak(\"Hi \"+sheet.cell(row_no,2).value+\", Welcome back.\")\n",
    "    except:\n",
    "        print(error)\n",
    "        speak(\"Something went wrong. Please Try again.\")\n",
    "            \n",
    "def voice():\n",
    "    speak(\"How may I help you?\")\n",
    "    word=recognize()\n",
    "    if(word==\"I want to check in\"):\n",
    "        value=checkIn()\n",
    "        if(value==\"midin\"):\n",
    "            speak(\"Do you want to mid in?\")\n",
    "            word=recognize()\n",
    "            if(word== \"yes\"):\n",
    "                midIn()\n",
    "            elif(word== \"no\"):\n",
    "                return None\n",
    "    elif(word==\"I want to check out\"):\n",
    "        value=checkOut()\n",
    "        if(value=='midout'):\n",
    "            speak(\"Do you want to mid out?\")\n",
    "            word=recognize()\n",
    "            if(word==\"yes\"):\n",
    "                midOut()\n",
    "            elif(word== \"no\"):\n",
    "                return None\n",
    "    elif(word==\"I want to mid in\"):\n",
    "        midIn()\n",
    "    elif(word==\"I want to mid out\"):\n",
    "        midOut()\n",
    "    else:\n",
    "        speak(\"Please give a valid command\")\n",
    "    \n",
    "btn1 = tkinter.Button(cv, text=\"Register\",font=('roboto',10),bg='#48bec5',fg='white',command=register)\n",
    "btn1.place(x=20,y=315)\n",
    "\n",
    "btn3 = tkinter.Button(cv, text=\"CHECK OUT\",font=('roboto',12),bg='#48bec5',fg='white',command=checkOut)\n",
    "btn3.pack(anchor=SE,side='right',ipadx=15,ipady=10,padx=10,pady=60)\n",
    "\n",
    "btn4 = tkinter.Button(cv, text=\"MID OUT\",font=('roboto',12),bg='#48bec5',fg='white',command=midOut)\n",
    "btn4.pack(anchor=SE,side='right',ipadx=15,ipady=10,padx=10,pady=60)\n",
    "\n",
    "btn5 = tkinter.Button(cv, text=\"MID IN\",font=('roboto',12),bg='#48bec5',fg='white',command=midIn)\n",
    "btn5.pack(anchor=SE,side='right',ipadx=15,ipady=10,padx=10,pady=60)\n",
    "\n",
    "btn2 = tkinter.Button(cv, text=\"CHECK IN\",font=('roboto',12),bg='#48bec5',fg='white',command=checkIn)\n",
    "btn2.pack(anchor=SE,side='right',ipadx=15,ipady=10,padx=10,pady=60)\n",
    "\n",
    "photo = PhotoImage(file='microphone-512.png').subsample(15,15)\n",
    "btn6 = Button(cv, image=photo, bd=0, bg='#48bec5', overrelief='groove', relief='sunken',command=voice)\n",
    "btn6.place(x=325,y=280,height=60, width=60)\n",
    "\n",
    "\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
